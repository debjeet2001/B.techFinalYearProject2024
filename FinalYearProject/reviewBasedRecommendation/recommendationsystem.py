# -*- coding: utf-8 -*-
"""recommendationSystem

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J3bi8Xih_7W2FzhOo6C2cICI4i1IdREN

# Import Libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import nltk
from sklearn.metrics import confusion_matrix

"""# Load and Inspect the Dataset"""

# Load the dataset
data = pd.read_csv('reviews.csv')

# Display the first few rows of the dataset
print(data.head())

"""# Preprocess Text Data"""

# Drop irrelevant columns (if any)
data.drop(['Name', 'Review Date', 'Verified', 'Type of Traveller', 'Month Flown'], axis=1, inplace=True)

# Convert text to lowercase
data['Reviews'] = data['Reviews'].str.lower()

# Remove punctuation and special characters
data['Reviews'] = data['Reviews'].str.replace('[^\w\s]', '')

# Tokenize text (split text into words)
data['Reviews'] = data['Reviews'].apply(lambda x: x.split())

# Remove stopwords (common words that do not carry much meaning)
from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
data['Reviews'] = data['Reviews'].apply(lambda x: [word for word in x if word not in stop_words])

# Convert tokens back to string
data['Reviews'] = data['Reviews'].apply(lambda x: ' '.join(x))

"""# Feature Extraction"""

# Define additional features
additional_features = ['Seat Comfort', 'Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Value For Money', 'Overall Rating']

# Extract additional features from the dataset
X_additional_features = data[additional_features]

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=1000)

# Fit and transform the text data
X_text = tfidf_vectorizer.fit_transform(data['Reviews'])

# Combine TF-IDF features with additional features
from scipy.sparse import hstack
X_combined = hstack((X_text, X_additional_features.values))

# Target variable
y = data['Recommended']

"""# Split Data into Train and Test Sets"""

X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

"""# Train the Gaussian Naive Bayes Model"""

# Initialize Gaussian Naive Bayes classifier
nb_classifier = GaussianNB()

# Train the classifier
nb_classifier.fit(X_train.toarray(), y_train)

"""# Train the Gradient Boosting Machine (GBM) Classifier"""

# Initialize Gradient Boosting Classifier
gbm_classifier = GradientBoostingClassifier(random_state=42)

# Train the classifier
gbm_classifier.fit(X_train.toarray(), y_train)

"""# Evaluate the Model- Gradient Boosting Machine (GBM) Classifier"""

# Make predictions on the test set
y_pred = gbm_classifier.predict(X_test.toarray())

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Print confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

"""# Ploting the graph for different ALGO vs ACCURACY

"""

algo=["naive bayes", "Gradient Boosting Machine-GBM"]
accuracies_plot=[0.85740740740, 0.94753086]
plt.bar(algo,accuracies_plot)
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
plt.title('Machine Learning Model Accuracies')
plt.show()